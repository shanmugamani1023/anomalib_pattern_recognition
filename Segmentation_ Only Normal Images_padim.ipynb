{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from anomalib import TaskType\n",
    "from anomalib.data import MVTec\n",
    "from anomalib.data.utils import read_image\n",
    "from anomalib.deploy import ExportType, OpenVINOInferencer\n",
    "from anomalib.engine import Engine\n",
    "from anomalib.models import Padim\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Shravtek\\\\neutech_airfillter\\\\anamolib'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Shravtek\\neutech_airfillter\\anamolib\\anomalib\n"
     ]
    }
   ],
   "source": [
    "cd anomalib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Shravtek\\\\neutech_airfillter\\\\anamolib\\\\anomalib'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datamodule\n",
    "# Import the datamodule\n",
    "from anomalib.data import Folder\n",
    "from anomalib.data.utils import TestSplitMode\n",
    "\n",
    "# Create the datamodule\n",
    "datamodule = Folder(\n",
    "    name=\"hazelnut_toy\",\n",
    "    root=\"datasets/hazelnut_toy\",\n",
    "    normal_dir=\"good\",\n",
    "    test_split_mode=TestSplitMode.SYNTHETIC,\n",
    "    image_size=(512,512)\n",
    ")\n",
    "\n",
    "# Setup the datamodule\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image_path', 'label', 'image', 'mask'])\n",
      "dict_keys(['image_path', 'label', 'image', 'mask'])\n",
      "dict_keys(['image_path', 'label', 'image', 'mask'])\n"
     ]
    }
   ],
   "source": [
    "i, train_data = next(enumerate(datamodule.train_dataloader()))\n",
    "print(train_data.keys())\n",
    "# dict_keys(['image_path', 'label', 'image'])\n",
    "\n",
    "i, val_data = next(enumerate(datamodule.val_dataloader()))\n",
    "print(val_data.keys())\n",
    "# dict_keys(['image_path', 'label', 'image'])\n",
    "\n",
    "i, test_data = next(enumerate(datamodule.test_dataloader()))\n",
    "print(test_data.keys())\n",
    "# dict_keys(['image_path', 'label', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Padim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start training\n",
    "# engine = Engine(task=TaskType.SEGMENTATION,accelerator=\"auto\",\n",
    "#     check_val_every_n_epoch=1,\n",
    "#     max_epochs=2,\n",
    "#     num_sanity_val_steps=0,\n",
    "#     val_check_interval=1.0\n",
    "#     )\n",
    "# engine.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "c:\\Users\\shan\\.conda\\envs\\anamo\\lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:180: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name                  | Type                     | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | model                 | PadimModel               | 2.8 M \n",
      "1 | _transform            | Compose                  | 0     \n",
      "2 | normalization_metrics | MinMax                   | 0     \n",
      "3 | image_threshold       | F1AdaptiveThreshold      | 0     \n",
      "4 | pixel_threshold       | F1AdaptiveThreshold      | 0     \n",
      "5 | image_metrics         | AnomalibMetricCollection | 0     \n",
      "6 | pixel_metrics         | AnomalibMetricCollection | 0     \n",
      "-------------------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.131    Total estimated model params size (MB)\n",
      "c:\\Users\\shan\\.conda\\envs\\anamo\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "c:\\Users\\shan\\.conda\\envs\\anamo\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8bdf25df7d4324a350a78ff452206f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shan\\.conda\\envs\\anamo\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:129: `training_step` returned `None`. If this was on purpose, ignore this warning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135b120c08284562b1f6a0c62af4fa6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04805e3f149747afbee2d8ca129b6e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5091292cfb2244b68b038e5b8ab4def6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "engine = Engine(task=TaskType.SEGMENTATION\n",
    "    )\n",
    "engine.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "Restoring states from the checkpoint path at D:\\Shravtek\\neutech_airfillter\\anamolib\\anomalib\\results\\Padim\\hazelnut_toy\\v5\\weights\\lightning\\model.ckpt\n",
      "Loaded model weights from the checkpoint at D:\\Shravtek\\neutech_airfillter\\anamolib\\anomalib\\results\\Padim\\hazelnut_toy\\v5\\weights\\lightning\\model.ckpt\n",
      "c:\\Users\\shan\\.conda\\envs\\anamo\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351a5a9f452f47d0b78b24229dd61562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        image_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">           0.75            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       image_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        pixel_AUROC        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.757884681224823     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       pixel_F1Score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.13023769855499268    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       image_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m          0.75           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      image_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       pixel_AUROC       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.757884681224823    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      pixel_F1Score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.13023769855499268   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results = engine.test(\n",
    "    model=model,\n",
    "    datamodule=datamodule,\n",
    "    ckpt_path=engine.trainer.checkpoint_callback.best_model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pixel_AUROC': 0.757884681224823,\n",
       "  'pixel_F1Score': 0.13023769855499268,\n",
       "  'image_AUROC': 0.75,\n",
       "  'image_F1Score': 0.0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shan\\.conda\\envs\\anamo\\lib\\site-packages\\torch\\onnx\\_internal\\jit_utils.py:307: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "c:\\Users\\shan\\.conda\\envs\\anamo\\lib\\site-packages\\torch\\onnx\\utils.py:702: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "c:\\Users\\shan\\.conda\\envs\\anamo\\lib\\site-packages\\torch\\onnx\\utils.py:1209: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Shravtek/neutech_airfillter/anamolib/anomalib/results/Padim/hazelnut_toy/latest/weights/openvino/model.xml')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.export(\n",
    "    model=model,\n",
    "    export_type=ExportType.OPENVINO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x201e0e36aa0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"D:/Shravtek/neutech_airfillter/anamolib/anomalib/datasets/hazelnut_toy/crack/01.jpg\"\n",
    "image = read_image(path=\"D:/Shravtek/neutech_airfillter/anamolib/anomalib/datasets/hazelnut_toy/crack/01.jpg\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Shravtek\\neutech_airfillter\\anamolib\\anomalib\\results\\Padim\\hazelnut_toy\\latest\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(engine.trainer.default_root_dir)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "openvino_model_path = output_path / \"weights\" / \"openvino\" / \"model.bin\"\n",
    "metadata = output_path / \"weights\" / \"openvino\" / \"metadata.json\"\n",
    "print(openvino_model_path.exists(), metadata.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer = OpenVINOInferencer(\n",
    "    path=openvino_model_path,  # Path to the OpenVINO IR model.\n",
    "    metadata=metadata,  # Path to the metadata file.\n",
    "    device=\"CPU\",  # We would like to run it on an Intel CPU.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = inferencer.predict(image=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4972085171740765 LabelName.NORMAL\n"
     ]
    }
   ],
   "source": [
    "print(predictions.pred_score, predictions.pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageResult(image=[[[228 214  79]\n",
      "  [231 217  82]\n",
      "  [231 217  82]\n",
      "  ...\n",
      "  [226 213  82]\n",
      "  [225 213  79]\n",
      "  [229 217  83]]\n",
      "\n",
      " [[228 214  79]\n",
      "  [228 214  79]\n",
      "  [229 215  80]\n",
      "  ...\n",
      "  [226 214  80]\n",
      "  [227 215  81]\n",
      "  [228 216  80]]\n",
      "\n",
      " [[230 217  79]\n",
      "  [230 217  79]\n",
      "  [229 216  78]\n",
      "  ...\n",
      "  [225 213  79]\n",
      "  [226 214  78]\n",
      "  [222 210  74]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[233 224  83]\n",
      "  [232 223  82]\n",
      "  [232 223  82]\n",
      "  ...\n",
      "  [223 211  73]\n",
      "  [223 211  73]\n",
      "  [222 210  72]]\n",
      "\n",
      " [[233 224  83]\n",
      "  [229 220  79]\n",
      "  [235 226  85]\n",
      "  ...\n",
      "  [225 214  73]\n",
      "  [223 212  71]\n",
      "  [224 213  72]]\n",
      "\n",
      " [[230 221  80]\n",
      "  [230 221  80]\n",
      "  [231 222  81]\n",
      "  ...\n",
      "  [219 208  67]\n",
      "  [221 210  69]\n",
      "  [226 215  74]]], pred_score=1.0, pred_label=1, anomaly_map=[[0.2643897  0.26474822 0.26583838 ... 0.26394427 0.2615446  0.2607414 ]\n",
      " [0.2644479  0.2648059  0.2658955  ... 0.2640093  0.2616168  0.26081592]\n",
      " [0.26464215 0.26499903 0.2660864  ... 0.26421773 0.2618471  0.2610533 ]\n",
      " ...\n",
      " [0.27315807 0.2730011  0.27252084 ... 0.23491961 0.23412982 0.2338576 ]\n",
      " [0.27061862 0.27045292 0.2699474  ... 0.2352978  0.23455444 0.23429784]\n",
      " [0.26976594 0.2695973  0.2690835  ... 0.2354284  0.23470089 0.23444948]], gt_mask=None, gt_boxes=None, pred_boxes=None, box_labels=None, pred_mask=[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]], heat_map=[[[137 184 149]\n",
      "  [139 186 151]\n",
      "  [139 186 151]\n",
      "  ...\n",
      "  [136 184 151]\n",
      "  [135 182 149]\n",
      "  [137 185 152]]\n",
      "\n",
      " [[137 184 149]\n",
      "  [137 184 149]\n",
      "  [137 185 150]\n",
      "  ...\n",
      "  [136 184 150]\n",
      "  [136 183 151]\n",
      "  [137 184 150]]\n",
      "\n",
      " [[138 186 149]\n",
      "  [138 186 149]\n",
      "  [137 186 149]\n",
      "  ...\n",
      "  [135 184 149]\n",
      "  [136 183 149]\n",
      "  [133 180 146]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[140 194 152]\n",
      "  [139 193 151]\n",
      "  [139 193 151]\n",
      "  ...\n",
      "  [134 170 146]\n",
      "  [134 170 146]\n",
      "  [133 169 145]]\n",
      "\n",
      " [[140 194 152]\n",
      "  [137 190 149]\n",
      "  [141 193 153]\n",
      "  ...\n",
      "  [135 173 146]\n",
      "  [134 170 145]\n",
      "  [134 171 145]]\n",
      "\n",
      " [[138 190 150]\n",
      "  [138 190 150]\n",
      "  [139 191 151]\n",
      "  ...\n",
      "  [131 170 142]\n",
      "  [133 169 143]\n",
      "  [136 172 146]]], segmentations=[[[227 214  79]\n",
      "  [231 217  81]\n",
      "  [231 217  81]\n",
      "  ...\n",
      "  [226 213  81]\n",
      "  [225 213  79]\n",
      "  [229 217  83]]\n",
      "\n",
      " [[227 214  79]\n",
      "  [227 214  79]\n",
      "  [229 215  80]\n",
      "  ...\n",
      "  [226 214  80]\n",
      "  [227 215  81]\n",
      "  [227 216  80]]\n",
      "\n",
      " [[230 217  79]\n",
      "  [230 217  79]\n",
      "  [229 216  78]\n",
      "  ...\n",
      "  [225 213  79]\n",
      "  [226 214  78]\n",
      "  [222 210  73]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[233 224  83]\n",
      "  [232 223  81]\n",
      "  [232 223  81]\n",
      "  ...\n",
      "  [223 211  73]\n",
      "  [223 211  73]\n",
      "  [222 210  72]]\n",
      "\n",
      " [[233 224  83]\n",
      "  [229 220  79]\n",
      "  [235 226  85]\n",
      "  ...\n",
      "  [225 214  73]\n",
      "  [223 211  71]\n",
      "  [224 213  72]]\n",
      "\n",
      " [[230 221  80]\n",
      "  [230 221  80]\n",
      "  [231 222  81]\n",
      "  ...\n",
      "  [219 208  67]\n",
      "  [221 210  69]\n",
      "  [226 215  73]]])\n"
     ]
    }
   ],
   "source": [
    "# Visualize the original image\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25b6cc924d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the segmentation mask.\n",
    "plt.imshow(predictions.pred_mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anamo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
